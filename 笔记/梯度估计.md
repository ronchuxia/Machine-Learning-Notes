[梯度估计——初步 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/104991140?utm_id=0)
[Probability distributions - torch.distributions — PyTorch 1.13 documentation](https://pytorch.org/docs/1.13/distributions.html?highlight=distributions#module-torch.distributions)

在 VAE 或强化学习中，我们需要优化一个与概率分布有关的目标函数：
$$J(\theta) = E_{x \sim p(x; \theta)}[f(x)] = \int p(x; \theta) f(x) dx$$

最直观的方法是求积分，得到显式的表达式后再求导，但这通常不可能。所以需要通过采样的方法进行梯度估计。

如果直接根据 $p(x; \theta)$ 采样，然后再求导，则采样过程不可微，无法反向传播梯度。有两种梯度估计的方法可以避免这个问题。

# Score Function Gradient Estimator / Likelihood Ratio Gradient Estimator / REINFORCE
将梯度从期望外移到期望内，从而可以通过采样的方法估计梯度：
$$\begin{align}
\nabla_\theta J(\theta) & = \nabla_\theta E_{x \sim p(x; \theta)}[f(x)]\\
& = \nabla_\theta \int p(x; \theta) f(x) dx\\
& = \int \nabla_\theta p(x; \theta) f(x) dx\\
& = \int p(x; \theta) \nabla_\theta \log p(x; \theta) f(x) dx\\
& = E_{x \sim p(x; \theta)}[\nabla_\theta \log p(x ;\theta) f(x)]
\end{align}$$

其中，$\nabla_\theta \log p(x; \theta)$ 称为得分函数，它度量了样本 $x$ 的对数概率对参数 $\theta$ 的敏感度，表示观测数据对参数更新的贡献或得分。

性质：
- 不需要 $f(x)$ 可微
- 需要 $p(x; \theta)$ 可微
- 方差一般较大，需要使用 baseline 等方法减小方差

# Pathwise Derivative
将参数 $\theta$ 从 $p(x; \theta)$ 中移到 $f(x)$ 中，从而可以通过采样的方法估计梯度：
$$\begin{align}
\nabla_\theta J(\theta) & = \nabla_\theta E_{x \sim p(x; \theta)}[f(x)]\\
& = \nabla_\theta \int p(x; \theta) f(x) dx\\
& = \nabla_\theta \int p(\epsilon) f(g(\epsilon; \theta)) dx\\
& = \int p(\epsilon) \nabla_\theta f(g(\epsilon; \theta)) dx\\
& = E_{\epsilon \sim p(\epsilon)} [\nabla_\theta f(g(\epsilon; \theta))] 
\end{align}$$

这种方法称为重参数化，其核心思想是将依赖参数的随机变量重参数化为一个确定的函数，外加一个从某个固定分布中采样的随机变量。这样可以通过链式法则直接对目标函数求导，而不再依赖于概率分布的导数。

性质：
- 需要 $f(x)$ 可微
- 需要 $g(\epsilon; \theta)$ 可微
- 不需要 $p(\epsilon)$ 可微

