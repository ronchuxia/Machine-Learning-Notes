# RCNN
## RCNN
1. **选择性搜索**（Selective Search），获取 **RoI**（Region of Interest）
	1. 初始化区域划分
	2. 基于颜色、纹理、尺寸、性质等特征合并相似的区域
2. 对每个 RoI，调整到相同的大小后使用 CNN 提取特征
3. 对特征使用 SVM 进行分类
4. 对特征使用线性回归进行边界框回归
缺点：慢。
## Fast RCNN
Fast RCNN 对 RCNN 做了三点改进：
- 对特征使用神经网络进行分类和边界框回归
- 仅对原图使用 CNN 提取特征，**通过将 RoI 映射到特征图上提取各个 RoI 的特征**
- 使用 **RoI Pooling** 将 RoI 池化到相同的大小（7 * 7）
	- Fix bin numbers
	- Do not fix bin size 
缺点：
- 仍使用选择性搜索查找 RoI，慢。
- RoI 映射和 RoI Pooling 时需要对小数坐标向下取整，引入了误差，因此对小物体检测不友好
## Faster RCNN
**使用 RPN 查找 RoI**：
- RPN 在特征图上滑动，为特征图上的每个点生成三种大小三种形状的 9 个框（Anchor）
- 对每个框进行打分（二分类）和边界框回归
- 取分数最高的几个框，经 NMS 算法合并后作为 RoI

**NMS 算法**：
1. 对所有 bbox 按 score 降序排序，选择 score 最高的一个 bbox 作为一个检测结果
2. 删除所有与 score 最高的 bbox 的 IoU 超过一定阈值的 bbox（同一个目标的 bbox）
3. 重复1-2，直到不再有候选的 bbox
## Mask RCNN
实例分割，为 Faster RCNN 输出的每个边界框生成 mask。

# YOLO
将图像分为多个小块，每个小块负责检测中心点在它之内的 1 个物体，并为这个物体回归 2 个 bbox。

# SSD
SSD 对 YOLO 做了三点改进：
- 利用多尺度特征图，大尺度特征图检测小物体，小尺度特征图检测大物体
- 利用卷积进行分类和边界框回归
- 利用 anchor 辅助网络训练，并且为每个 anchor 都预测一个类别

# DETR
![[Pasted image 20230823195631.png]]
它首先用Resnet提取特征图，计算特征图Positional Encoding，然后将其输入到下图所示的Transformer结构中。与Transformer不同，DETR的Decoder可以同时绘制特定数量个Bounding Box（不需要attn_mask）。原理如下：
- Encoder由特征图提供qkv，从而学习特征图中各个部位的特征。
- Decoder Self-attention由Bounding Box提供qkv，从而整合各个Bounding Box的特征。
- Decoder Attention由Bounding Box提供q，由特征图提供kv，从而让各个Bounding Box整合特征图中各个部位的特征。
![[Pasted image 20230823200419.png]]
部分实现细节如下：
- Object Queries初始化为0，在每次做attention前添加Positional Encoding。
- 可以做多监督，对于Transformer Decoder的每一层输出，都可以回归Bounding Box并分类，计算损失。

## MultiHeadAttention模块
- query: $(L, N, E_q)$，L为query序列的长度
- key/value: $(S, N, E_{k/v})$，S为key/value序列的长度
- key_padding_mask: $(N, S)$，key/value序列中哪些位置是padding
- attn_mask: $(L, S)$，query序列中每个位置和key/value序列中的哪些位置做attention

# Deformable DETR
## DETR的缺点
- 由于Transformer的限制，特征图的分辨率不能太高，这导致DETR对小物体的检测效果不好。
- 一开始，特征图中各像素的attention差不多，需要多个epoch的迭代才能获得较好的attention，训练速度慢。

## Multi-scale