ICA 基于以下假设：
- 源数据 $s \in \mathbb{R}^n$ 由 n 个**独立同分布**的数据源生成
- 观测数据 $x \in \mathbb{R}^n$ 由源数据**线性组合**而成，即 $x = As$ 
- 观测数据集 $\{x^{(i)}; i = 1, 2, \cdots, m\}$ 由 m 个独立的观测数据组成
其中，方阵 $A$ 称为 mixing matrix。

ICA 的目的是，找到方阵 $W = A^{-1}$，使得我们可以根据观测数据 $x$ 恢复出源数据 $s = Wx$。其中，方阵 $W$ 称为 unmixing matrix。

# ICA Ambiguities
对于非高斯分布的数据，ICA 存在两种歧义性：
- 源数据的顺序有歧义（只要交换 $W$ 中对应的行）
- 源数据的缩放有歧义（只要缩放 $W$ 中对应的列）
对于一些应用，这两种歧义性没有影响。

对于高斯分布的数据，假设 $s \sim \mathcal{N}(0, I)$，$x = As$，则 $x$ 服从高斯分布，其均值为 0，方差为 $E[xx^T] = E[Ass^TA^T] = AA^T$。假设 $R$ 为任意的正交矩阵（旋转矩阵或反射矩阵），$A' = AR$，$x' = A's$，则 $E[x' (x')^T] = E[A'ss^T(a')^T] = E[ARss^TR^TA^T] = ARR^TA^T = AA^T$。则 $A'$ 也是可能的 mixing matrix。即对于高斯分布的数据，因为高斯分布具有旋转不变性，所以我们无法确定观测数据的坐标系，因此无法使用 ICA。

# Density and Linear Transformations
如果 $s = Wx$，且 $s$ 的概率密度函数为 $p_s$，则 $x$ 的概率密度函数为：
$$p_x(x) = p_s(Wx) \cdot |W|$$

注：如果 $C_1 = [0, 1]^n$ 为 n 维超立方体，$C_2 = \{ As : s \in C_1\}$ 为 $C_1$ 在映射 $A$ 下的像，则 $C_2$ 的体积为 $|A|$。

#  ICA Algorithm
因为 ICA 假设源数据的各个维度独立，$s$ 的联合分布为：
$$p(s) = \prod_{i = 1}^n p_s(s_i)$$

根据线性变换的概率密度公式：
$$p(x) = \prod_{i = 1}^n p_s(w_i^T x) \cdot |W|$$

对于已知分布的源数据，我们使用其分布的概率密度函数。对于未知分布的源数据，我们**使用 sigmoid 函数 $g(s)$ 作为其累计分布函数**，即使用 $g'(s)$ 作为其概率密度函数。

如果使用 sigmoid 函数 $g(s)$ 作为源数据的累计分布函数，因为 $E[s] = 0$，所以 $E[x] = E[As] = 0$。因此，需要先要对数据做**归一化**，将数据的均值归一化为 0。

ICA 最大化观测数据的对数似然函数。因为 ICA 假设观测数据独立，观测数据的对数似然函数为：
$$l(W) = \sum_{i = 1}^m \left( \sum_{j = 1}^n \log g'(w_j^T x^{(i)}) + \log |W| \right)$$

使用随机梯度下降最大化观测数据的对数似然函数。随机梯度下降的参数更新公式为：
$$W := W + \alpha \left( \begin{bmatrix}
1 - 2 g(w_1^T x^{(i)}))\\
1 - 2 g(w_2^T x^{(i)}))\\
\vdots\\
1 - 2 g(w_n^T x^{(i)}))\\
\end{bmatrix} {x^{(i)}}^T + (W^T)^{-1} \right)$$

注：对于一些形式的观测数据，如时间序列，观测数据集中的观测数据通常不是独立的。但只要有足够的数据，ICA 就能达到较好的效果。对于这类数据，打乱观测数据集中的观测数据的顺序也会有助于 ICA 收敛。



