# CLIP (Contrastive Language-Image Pre-training)
文本指导的图像分类。
1. 对比学习预训练
	提取文本特征和图像特征，最大化匹配的文本-图像特征对的余弦相似度，同时最小化不匹配的文本-图像特征对的余弦相似度
2. 构建 prompt
	由于训练集中的文本并不仅由 label 组成，因此推理时也需要根据 label 构建 prompt，并提取 prompt 的文本特征
3. 进行分类
	提取图像特征，与文本特征计算余弦相似度，最相似的 label 即为分类结果
![](https://images.openai.com/blob/fbc4f633-9ad4-4dc2-bd94-0b6f1feee22f/overview-a.svg?width=10&height=10&quality=50)
![](https://images.openai.com/blob/d9d46e4b-6d6a-4f9e-9345-5c6538b1b8c3/overview-b.svg?width=10&height=10&quality=50)

# DALLE
[DALL·E—从文本到图像，超现实主义的图像生成器 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/394467135)
Stage 1
1. 使用 **dVAE**（类似VQVAE）encoder 将 256 * 256 的图像编码为 32 * 32 * 8096 的 **latent code**（图像特征），并用 dVAE decoder 将 latent code 还原为图像
2. 训练 dVAE，学习 **codebook**
Stage 2
1. 使用 transfomer 提取文本特征
2. 将文本特征与图像特征拼接，将拼接后的特征交给 **GPT** 进行训练，从而可以根据输入的文本特征生成图像特征
3. 将图像特征交给 dVAE decoder 还原图像
 
