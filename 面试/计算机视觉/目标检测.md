# YOLO
将图像分为多个小块，每个小块预测多个中心点在它之内的 bbox
NMS
1. 对所有 bbox 按 score 降序排序，选择 score 最高的一个 bbox 作为一个检测结果
2. 删除所有与 score 最高的 bbox 的 IoU 超过一定阈值的 bbox（同一个目标的 bbox）
3. 重复1-2，直到不再有候选的 bbox

# RCNN
## RCNN
基本原理：
1. **选择性搜索**，获取 **RoI**（Region of Interest）
	1. 初始化区域划分
	2. 基于颜色、纹理、尺寸、性质等特征合并相似的区域
2. 对每个 RoI，调整大小后使用 CNN 提取特征
3. 对特征使用 SVM 分类
4. 对特征使用线性回归预测边界框
缺点：慢。
## Fast RCNN
仅对原图使用 CNN 提取特征，**通过将 RoI 映射到特征图上提取各个 RoI 的特征**。
TODO：RoI 映射、RoI Pooling
缺点：仍使用选择性搜索查找 RoI，慢。
## Faster RCNN
**使用 RPN 查找 RoI**。RPN在这些特征图上使用滑动窗口，每个窗口生成不同形状和大小的 k 个方框（Anchor box）。

# DETR
![[Pasted image 20230823195631.png]]
它首先用Resnet提取特征图，计算特征图Positional Encoding，然后将其输入到下图所示的Transformer结构中。与Transformer不同，DETR的Decoder可以同时绘制特定数量个Bounding Box（不需要attn_mask）。原理如下：
- Encoder由特征图提供qkv，从而学习特征图中各个部位的特征。
- Decoder Self-attention由Bounding Box提供qkv，从而整合各个Bounding Box的特征。
- Decoder Attention由Bounding Box提供q，由特征图提供kv，从而让各个Bounding Box整合特征图中各个部位的特征。
![[Pasted image 20230823200419.png]]
部分实现细节如下：
- Object Queries初始化为0，在每次做attention前添加Positional Encoding。
- 可以做多监督，对于Transformer Decoder的每一层输出，都可以回归Bounding Box并分类，计算损失。

## MultiHeadAttention模块
- query: $(L, N, E_q)$，L为query序列的长度
- key/value: $(S, N, E_{k/v})$，S为key/value序列的长度
- key_padding_mask: $(N, S)$，key/value序列中哪些位置是padding
- attn_mask: $(L, S)$，query序列中每个位置和key/value序列中的哪些位置做attention

# Deformable DETR
## DETR的缺点
- 由于Transformer的限制，特征图的分辨率不能太高，这导致DETR对小物体的检测效果不好。
- 一开始，特征图中各像素的attention差不多，需要多个epoch的迭代才能获得较好的attention，训练速度慢。

## Multi-scale